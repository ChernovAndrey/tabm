seed = 0
function = "_bin.model.main"
n_trials = 100

[sampler]
n_startup_trials = 20

[space]
seed = 0
batch_size = 256
patience = 16
n_epochs = -1
gradient_clipping_norm = 1.0
amp = true

[space.data]
cache = true
path = "data/regression-num-medium-0-pol"
num_policy = "noisy-quantile"

[space.optimizer]
type = "AdamW"
lr = [
    "_tune_",
    "loguniform",
    0.0001,
    0.005,
]
weight_decay = [
    "_tune_",
    "?loguniform",
    0.0,
    0.0001,
    0.1,
]

[space.model]
arch_type = "tabm-mini"
k = 32

[space.model.backbone]
type = "BMoE"
n_blocks = [
    "_tune_",
    "int",
    1,
    4,
]
d_block = [
    "_tune_",
    "int",
    512,
    4096,
    256,
]
dropout = [
    "_tune_",
    "?uniform",
    0.0,
    0.0,
    0.5,
]
d_block_per_expert = 128
default_num_samples = 10
tau = [
    "_tune_",
    "uniform",
    0.5,
    3.0,
]
gating_type = "bayesian"

[space.model.num_embeddings]
type = "PiecewiseLinearEmbeddings"
d_embedding = [
    "_tune_",
    "int",
    8,
    32,
    4,
]

[space.bins]
n_bins = [
    "_tune_",
    "int",
    2,
    128,
]
