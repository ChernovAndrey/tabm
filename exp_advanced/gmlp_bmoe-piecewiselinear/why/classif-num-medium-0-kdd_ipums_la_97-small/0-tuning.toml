seed = 0
function = "_bin.model.main"
n_trials = 100

[sampler]
n_startup_trials = 20

[space]
seed = 0
batch_size = 64
patience = 16
n_epochs = -1
gradient_clipping_norm = 1.0
amp = true

[space.data]
cache = true
path = "data/classif-num-medium-0-kdd_ipums_la_97-small"
num_policy = "noisy-quantile"

[space.optimizer]
type = "AdamW"
lr = [
    "_tune_",
    "loguniform",
    0.0003,
    0.01,
]
weight_decay = [
    "_tune_",
    "?loguniform",
    0.0,
    0.0001,
    0.1,
]

[space.model]
arch_type = "plain"

[space.model.backbone]
type = "BMoE"
n_blocks = [
    "_tune_",
    "int",
    1,
    5,
]
d_block = [
    "_tune_",
    "int",
    128,
    1280,
    64,
]
dropout = [
    "_tune_",
    "?uniform",
    0.0,
    0.0,
    0.5,
]
d_block_per_expert = [
    "_tune_",
    "int",
    32,
    64,
    32,
]
default_num_samples = 10
tau = [
    "_tune_",
    "uniform",
    0.5,
    3.0,
]
expert_type = "gMLP"
gating_type = "bayesian"

[space.model.num_embeddings]
type = "PiecewiseLinearEmbeddings"
d_embedding = [
    "_tune_",
    "int",
    8,
    32,
    4,
]

[space.bins]
n_bins = [
    "_tune_",
    "int",
    2,
    128,
]
